{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0Kel9+UZiohRKrSWHcvTJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakshmic/Stanford-TECH-16/blob/main/lesson1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4YxJGHnmCOn",
        "outputId": "b38e860f-83e3-4ec6-f830-a7c7a0e5471e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.13-py3-none-any.whl (328 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.13\n"
          ]
        }
      ],
      "source": [
        "%pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "open_ai_key = userdata.get('openAI')"
      ],
      "metadata": {
        "id": "BHZmPUfx58X_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "zOYrFgyj6YMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(message):\n",
        "  client = OpenAI(api_key=open_ai_key)\n",
        "  response = client.chat.completions.create(model=\"gpt-3.5-turbo\",\n",
        "                                            messages=[\n",
        "                                                {\"role\": \"system\", \"content\": \"Summarize the text into a headline\"},\n",
        "                                                {\"role\": \"user\", \"content\": f\"{message}\"},\n",
        "                                            ]\n",
        "                                            )\n",
        "  print (response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "rL1rj37e6o1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(message):\n",
        "  client = OpenAI(api_key=open_ai_key)\n",
        "  response = client.chat.completions.create(model=\"gpt-3.5-turbo\",\n",
        "                                            messages=[\n",
        "                                                {\"role\": \"system\", \"content\": \"Summarize the text into a headline\"},\n",
        "                                                {\"role\": \"user\", \"content\": f\"{message}\"},\n",
        "                                            ]\n",
        "                                            )\n",
        "  return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "6fa-rjosbC30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Read the summary from a hard coded content message"
      ],
      "metadata": {
        "id": "Akk5q81ihDY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message = \"\"\"Featured\n",
        "Topics\n",
        "Newsletters\n",
        "Events\n",
        "Podcasts\n",
        "SIGN IN\n",
        "SUBSCRIBE\n",
        "ARTIFICIAL INTELLIGENCE\n",
        "Large language models can do jaw-dropping things. But nobody knows exactly why.\n",
        "And that's a problem. Figuring it out is one of the biggest scientific puzzles of our time and a crucial step towards controlling more powerful future models.\n",
        "\n",
        "By Will Douglas Heavenarchive page\n",
        "March 4, 2024\n",
        "an eye looks through a keyhole ringed by Markov chain notations\n",
        "STEPHANIE ARNETT | MIDJOURNEY (EYE)\n",
        "Two years ago, Yuri Burda and Harri Edwards, researchers at the San Francisco–based firm OpenAI, were trying to find out what it would take to get a language model to do basic arithmetic. They wanted to know how many examples of adding up two numbers the model needed to see before it was able to add up any two numbers they gave it. At first, things didn’t go too well. The models memorized the sums they saw but failed to solve new ones.\n",
        "\n",
        "By accident, Burda and Edwards left some of their experiments running far longer than they meant to—days rather than hours. The models were shown the example sums over and over again, way past the point when the researchers would otherwise have called it quits. But when the pair at last came back, they were surprised to find that the experiments had worked. They’d trained a language model to add two numbers—it had just taken a lot more time than anybody thought it should.\n",
        "\n",
        "Curious about what was going on, Burda and Edwards teamed up with colleagues to study the phenomenon. They found that in certain cases, models could seemingly fail to learn a task and then all of a sudden just get it, as if a lightbulb had switched on. This wasn’t how deep learning was supposed to work. They called the behavior grokking.\n",
        "\n",
        "“It’s really interesting,” says Hattie Zhou, an AI researcher at the University of Montreal and Apple Machine Learning Research, who wasn’t involved in the work. “Can we ever be confident that models have stopped learning? Because maybe we just haven’t trained for long enough.”\n",
        "\n",
        "\n",
        "The weird behavior has captured the imagination of the wider research community. “Lots of people have opinions,” says Lauro Langosco at the University of Cambridge, UK. “But I don’t think there’s a consensus about what exactly is going on.”\n",
        "\n",
        "Related Story\n",
        "silohouette of a figure merged with a circuit board that has a Raven&#039;s test diagram printed on it\n",
        "AI hype is built on high test scores. Those tests are flawed.\n",
        "With hopes and fears about the technology running wild, it's time to agree on what it can and can't do.\n",
        "\n",
        "Grokking is just one of several odd phenomena that have AI researchers scratching their heads. The largest models, and large language models in particular, seem to behave in ways textbook math says they shouldn’t. This highlights a remarkable fact about deep learning, the fundamental technology behind today’s AI boom: for all its runaway success, nobody knows exactly how—or why—it works.\n",
        "\n",
        "“Obviously, we’re not completely ignorant,” says Mikhail Belkin, a computer scientist at the University of California, San Diego. “But our theoretical analysis is so far off what these models can do. Like, why can they learn language? I think this is very mysterious.”\n",
        "\n",
        "The biggest models are now so complex that researchers are studying them as if they were strange natural phenomena, carrying out experiments and trying to explain the results. Many of those observations fly in the face of classical statistics, which had provided our best set of explanations for how predictive models behave.\n",
        "\n",
        "So what, you might say. In the last few weeks, Google DeepMind has rolled out its generative models across most of its consumer apps. OpenAI wowed people with Sora, its stunning new text-to-video model. And businesses around the world are scrambling to co-opt AI for their needs. The tech works—isn’t that enough?\n",
        "\n",
        "But figuring out why deep learning works so well isn’t just an intriguing scientific puzzle. It could also be key to unlocking the next generation of the technology—as well as getting a handle on its formidable risks.\n",
        "\n",
        "“These are exciting times,” says Boaz Barak, a computer scientist at Harvard University who is on secondment to OpenAI’s superalignment team for a year. “Many people in the field often compare it to physics at the beginning of the 20th century. We have a lot of experimental results that we don’t completely understand, and often when you do an experiment it surprises you.”\n",
        "\n",
        "Old code, new tricks\n",
        "Most of the surprises concern the way models can learn to do things that they have not been shown how to do. Known as generalization, this is one of the most fundamental ideas in machine learning—and its greatest puzzle. Models learn to do a task—spot faces, translate sentences, avoid pedestrians—by training with a specific set of examples. Yet they can generalize, learning to do that task with examples they have not seen before. Somehow, models do not just memorize patterns they have seen but come up with rules that let them apply those patterns to new cases. And sometimes, as with grokking, generalization happens when we don’t expect it to.\n",
        "\n",
        "Large language models in particular, such as OpenAI’s GPT-4 and Google DeepMind’s Gemini, have an astonishing ability to generalize. “The magic is not that the model can learn math problems in English and then generalize to new math problems in English,” says Barak, “but that the model can learn math problems in English, then see some French literature, and from that generalize to solving math problems in French. That’s something beyond what statistics can tell you about.”\n",
        "\n",
        "When Zhou started studying AI a few years ago, she was struck by the way her teachers focused on the how but not the why. “It was like, here is how you train these models and then here’s the result,” she says. “But it wasn’t clear why this process leads to models that are capable of doing these amazing things.” She wanted to know more, but she was told there weren’t good answers: “My assumption was that scientists know what they’re doing. Like, they’d get the theories and then they’d build the models. That wasn’t the case at all.”\n",
        "\n",
        "\n",
        "The rapid advances in deep learning over the last 10-plus years came more from trial and error than from understanding. Researchers copied what worked for others and tacked on innovations of their own. There are now many different ingredients that can be added to models and a growing cookbook filled with recipes for using them. “People try this thing, that thing, all these tricks,” says Belkin. “Some are important. Some are probably not.”\n",
        "\n",
        "“It works, which is amazing. Our minds are blown by how powerful these things are,” he says. And yet for all their success, the recipes are more alchemy than chemistry: “We figured out certain incantations at midnight after mixing up some ingredients,” he says.\n",
        "\n",
        "Overfitting\n",
        "The problem is that AI in the era of large language models appears to defy textbook statistics. The most powerful models today are vast, with up to a trillion parameters (the values in a model that get adjusted during training). But statistics says that as models get bigger, they should first improve in performance but then get worse. This is because of something called overfitting.\n",
        "\n",
        "When a model gets trained on a data set, it tries to fit that data to a pattern. Picture a bunch of data points plotted on a chart. A pattern that fits the data can be represented on that chart as a line running through the points. The process of training a model can be thought of as getting it to find a line that fits the training data (the dots already on the chart) but also fits new data (new dots).\"\"\"\n",
        "my_summary = summarize(message)\n",
        "print(\"Summary is \")\n",
        "print(my_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYmoMHj2HBKG",
        "outputId": "07600544-4743-4d3b-c05e-ad107bba938b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary is \n",
            "Scientists Explore the Mystery Behind the Fascinating Capabilities of Large Language Models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Split the String into chunks of 2048 to avoid RateLimitError"
      ],
      "metadata": {
        "id": "yDNnzFbFnpxv"
      }
    },
    {
      "source": [
        "def split_into_chunks(content, chunk_size=2048):\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(content):\n",
        "        end = start + chunk_size\n",
        "        chunks.append(content[start:end])\n",
        "        start = end\n",
        "    return chunks\n",
        "\n",
        "# Assuming 'content' is the string you obtained in the previous step\n",
        "chunks = split_into_chunks(content)\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "9jK9Lp0Yersd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read from a URL"
      ],
      "metadata": {
        "id": "y37UEt0rcMbm"
      }
    },
    {
      "source": [
        "!pip install beautifulsoup4\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def extract_text_from_url(url):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        # Extract all text from the parsed HTML\n",
        "        text = soup.get_text(separator=' ', strip=True)\n",
        "        return text\n",
        "    else:\n",
        "        return None\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFxjgDM3jf_L",
        "outputId": "e3935dda-5abd-4706-bf3b-2836574cb19a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Final Execution without chunking"
      ],
      "metadata": {
        "id": "Xmpjm1R_nvIV"
      }
    },
    {
      "source": [
        "import requests\n",
        "\n",
        "url = 'https://hai.stanford.edu/news/how-much-research-being-written-large-language-models'\n",
        "\n",
        "\n",
        "final_summary = []\n",
        "extracted_text = extract_text_from_url(url)\n",
        "if extracted_text:\n",
        "    print(summarize(extracted_text))\n",
        "\n",
        "else:\n",
        "    print('Failed to retrieve content from URL.')\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNcX7NjWdYjO",
        "outputId": "006b8320-316e-47f5-e1ba-dfbd8eb91406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Large Language Models Transforming Research with Increase in Usage in Academia, Stanford Study Finds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Summary with chunking\n"
      ],
      "metadata": {
        "id": "BLeCMdrBn_zQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://hai.stanford.edu/news/how-much-research-being-written-large-language-models'\n",
        "\n",
        "\n",
        "final_summary = []\n",
        "extracted_text = extract_text_from_url(url)\n",
        "if extracted_text:\n",
        "\n",
        "    chunks = split_into_chunks(extracted_text)\n",
        "    for chunk in chunks:\n",
        "      cur_summary = summarize(f\"\"\"{chunk}\"\"\")\n",
        "      print(cur_summary)\n",
        "      final_summary.append(cur_summary)\n",
        "\n",
        "else:\n",
        "    print('Failed to retrieve content from URL.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJwgcXuTn1z5",
        "outputId": "2c427d33-4b0b-4c16-c8e1-8765e64d2637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Large Language Models Are Producing an Abundance of Research\n",
            "Study Shows Surge in Language Model Usage in Academia, Particularly in Computer Science: Implications for Researchers and Reviewers\n",
            "Stanford Research Shows High Usage of Language Models in Scientific Papers\n",
            "Study Shows AI Impact on Peer Reviews of AI Conference Papers\n",
            "Ethical implications of Language Models in Academic Writing: Rise in Usage and Varying Policies Among Journals\n",
            "Increasing Number of Papers Overwhelming Reviewers and Authors in Artificial Intelligence and Computer Science Disciplines\n",
            "Rapid adoption of AI language models in humanities journals raises concerns about review quality\n",
            "LLMs in Research: Necessity of Transparency and Accountability\n",
            "Stanford University's HAI Collaborates with AI Experts to Advance Research and Improve Human Condition\n",
            "Stanford University: Terms of Use, Privacy, and Copyright Information\n"
          ]
        }
      ]
    }
  ]
}